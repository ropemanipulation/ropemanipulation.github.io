<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<link rel="StyleSheet" href="style.css" type="text/css" media="all" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Rope Manipulation</title>
<style type="text/css">
#primarycontent h1 {
  font-variant: small-caps;
}
#primarycontent h3 {
}
#primarycontent teasertext {
  text-align: center;
}
#primarycontent p {
  text-align: center;
}
#primarycontent {
  text-align: justify;
}
#primarycontent p {
  text-align: justify;
  padding-left: 10px;
  padding-right: 10px;
}
#primarycontent p iframe {
  text-align: center;
}
.featart {
  margin:4px;
}
.hoverdiv {
  background-color:black;
  margin-top:2px;
  margin-bottom:10px;
  width:100%;
}
.hoverdiv:hover {
  background-color:white;
}
</style>

<script type="text/javascript">
  function togglevis(elid){
    el=document.getElementById(elid);
    aelid=elid+"a";
    ael=document.getElementById(aelid);
    if(el.style.display=='none'){
      el.style.display='inline-table';
      ael.innerHTML="[Hide BibTex]";
    }else{
      el.style.display='none';
      ael.innerHTML="[Show BibTex]";
    }
  }
</script>
<script type="text/javascript"
  src="http://www.maths.nottingham.ac.uk/personal/drw/LaTeXMathML.js">
</script>
<!--
<script type="text/javascript" src="http://math.etsu.edu/LaTeXMathML/LaTeXMathML.js"></script>
<link rel="stylesheet" type="text/css" href="http://math.etsu.edu/LaTeXMathML/LaTeXMathML.standardarticle.css" />
-->

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-79839829-1', 'auto');
  ga('send', 'pageview');

</script>

</head>
<body>
<div id="primarycontent">
<h1 align="center" itemprop="name"><strong>Combining Self-Supervised Learning and Imitation<br />for Vision-Based Rope Manipulation</strong></h1>

<center>
<ul id="people" itemprop="accountablePerson">
	<li><h4>
        <a href="https://github.com/anair13">Ashvin Nair*</a>,
        <a href="https://github.com/dianchen96">Dian Chen*</a>,
        <a href="http://people.eecs.berkeley.edu/~pulkitag">Pulkit Agrawal*</a>,
        <a href="http://web.mit.edu/phillipi">Phillip Isola</a>,
        <a href="http://people.eecs.berkeley.edu/~pabbeel">Pieter Abbeel</a>,
        <a href="http://people.eecs.berkeley.edu/~malik">Jitendra Malik</a>,
        <a href="http://homes.cs.washington.edu/~svlevine/">Sergey Levine</a></h4></li>
  <li>*Equal Contribution</li>
</ul>
</center>

<img src="img/fig1_cropped.jpg" itemprop="image" width="800" alt="teaserImage">

<h3>Abstract</h3>
<p>We present a system where a robot takes as input a sequence of images of a human manipulating a rope from an initial to goal configuration, and outputs a sequence of actions that can reproduce the human demonstration, using only monocular images as input. To perform this task, the robot learns a pixel-level inverse dynamics model of rope manipulation directly from images in a self-supervised manner, using more than 30K interactions with the rope collected autonomously by the robot. The human demonstration provides a high-level plan of what to do and the low-level inverse model is used to execute the plan. We show that by combining the high and low-level plans, the robot can successfully manipulate a rope into a variety of target shapes using only a sequence of human-provided images for direction.
</p>

<h3>Paper</h3>
<p style="padding-left: 10px; padding-right: 10px;">
    The paper is available at: <a href='https://arxiv.org/abs/1703.02018'>[pdf]</a>
</p>

<h3 style="clear:both">Data</h3>
<p style="padding-left: 10px; padding-right: 10px;">
The data used for training the inverse dynamics model is available <a href="https://drive.google.com/open?id=0B3xZefNMOTwuUnU2MWVYeFdyUGM">here</a>. Instructions on how to access the data and use our validation set for evaluating the accuracy of the learnt model are included in an iPython notebook <a href="https://drive.google.com/open?id=0B3xZefNMOTwuSGlqakhlMkNmUFE">here</a>.
</p>

<h3>Video</h3>
<table style="margin: 0 auto">
  <tr>
  <p style="padding-left: 10px; padding-right: 10px;">
  This video explains our method and shows our experimental results.
  </p>
    <td>
     <iframe width="640" height="360" src="https://www.youtube.com/embed/ofNQh5ELrOw" frameborder="0" allowfullscreen></iframe>
    </td>
  </tr>
</table>

<h3>Robot's Rope Manipulation Skills</h3>
<table style="margin: 0 auto">
  <tr>
  <p style="padding-left: 10px; padding-right: 10px;">
  The following videos show randomly sampled success and failure examples of our robot at  manipulating the rope into L, S, W shapes and in tying knots.
  </p>
    <td>
     <iframe src="https://www.youtube.com/embed/IZwCc3gwirs?ecver=2" width="640" height="360" frameborder="0" allowfullscreen></iframe>
    </td>
  </tr>
  <tr>
  <tr><p>
  </p></tr>
  <tr>
    <td>
     <iframe src="https://www.youtube.com/embed/dSVr7WMxT9c?ecver=2" width="640" height="360" frameborder="0" allowfullscreen></iframe>
    </td>
  </tr>
  <tr><p>
  </p></tr>
  <tr>
    <td>
     <iframe src="https://www.youtube.com/embed/qOUFzsuWAMc?ecver=2" width="640" height="360" frameborder="0" allowfullscreen></iframe>
    </td>
  </tr>
  <tr>
    <td>
     <iframe src="https://www.youtube.com/embed/xI9AvSpc884?ecver=2" width="640" height="360" frameborder="0" allowfullscreen></iframe>
    </td>
  </tr>
</table>

<h3>Generalization Experiments</h3>
<table style="margin: 0 auto">
  <tr>
  <p style="padding-left: 10px; padding-right: 10px;">
  We tested the learnt model for manipulating two different ropes - (i) stiffer white rope and (ii) a softer black rope. Our model is succesfully able to manipulate these ropes into "S" and "L" shapes. This is very interesting because our model was trained using data from only a single red rope. While our model is sucessful at manipulating different ropes into "S" and "L" shapes it is unsucessful at forming knots or the "W" shape. One possible reason for this failure is that the white rope is too stiff to be bent into these shapes. Since our model was trained using only a single (green) background it doesnot generalizes to new backgrounds. If provided with substantially more robot-hours and a greater variety of ropes and environments, our  model could in principle learn a more generalizable notion of rope manipulation.
  </p>
    <td>
     <iframe src="https://www.youtube.com/embed/XW5zwTssWoo?ecver=2" width="640" height="360" frameborder="0" allowfullscreen></iframe>
    </td>
  </tr>
</table>

<h3>Link to videos</h3>
<p style="padding-left: 10px; padding-right: 10px;">All videos above can be accessed <a href="https://drive.google.com/open?id=0B_yFyQ8wPSh8YURfc2VkVDNJVEU">here</a>.</p>

<h3>Link to prior work</h3>
<p style="padding-left: 10px; padding-right: 10px;">Our previous project on model learning and large-scale data collection can be viewed <a href="http://ashvin.me/pokebot-website/">here</a>.</p>

<h3 style="clear:both">Website Template</h3>
<p style="padding-left: 10px; padding-right: 10px;">
The template for this website has been adopted from Carl Doersch.
</p>

<h3 style="clear:both">Contact</h3>
<p style="padding-left: 10px; padding-right: 10px;">
For comments/questions, contact <a href="https://www.cs.berkeley.edu/~pulkitag">Pulkit Agrawal</a></p>
</div>

</body>
</html>
